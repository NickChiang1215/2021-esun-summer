{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"SAM_efficient_training_tpu_整理.ipynb","private_outputs":true,"provenance":[{"file_id":"19c060KkqiSehVapst1ivAM5nkaujC8F7","timestamp":1624239862181},{"file_id":"1G8hcLw2XOfnvmHtxdXGAwBVcHYoxPgPs","timestamp":1623584543160}],"collapsed_sections":[]},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"OBlg0aBDETy2"},"source":["# 參考 https://github.com/sayakpaul/Sharpness-Aware-Minimization-TensorFlow"],"id":"OBlg0aBDETy2","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_tXY_Nj53zIW"},"source":["!pip install tensorflow_addons\n","!pip install focal_loss"],"id":"_tXY_Nj53zIW","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7EtCMx7tGxhZ"},"source":["# 因使用TPU模型必須需放在gcp storage上，這步驟需要給google colab存取gcp storage的權限\n","from google.colab import auth\n","import os\n","auth.authenticate_user()\n","project_id = 'intrepid-vista-285204' # 需依照自己的project name命名\n","!gcloud config set project {project_id}"],"id":"7EtCMx7tGxhZ","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oDB-HGD8owIi"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","os.chdir('/content/drive/MyDrive/T-Brain') #更改路徑"],"id":"oDB-HGD8owIi","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RwTTYnX6c4M5"},"source":[""],"id":"RwTTYnX6c4M5","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"promotional-skill"},"source":["import os\n","import PIL\n","import PIL.Image\n","import pickle\n","import os\n","import re\n","\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.applications import EfficientNetB0\n","from tensorflow.keras.callbacks import LearningRateScheduler\n","from sklearn.utils import class_weight\n","from focal_loss import SparseCategoricalFocalLoss\n","\n","import autoaugment\n","\n","tf.config.set_soft_device_placement(True)"],"id":"promotional-skill","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1AYjQGoU2gFi"},"source":["try:\n","    resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n","    tf.config.experimental_connect_to_cluster(resolver)\n","    # This is the TPU initialization code that has to be at the beginning.\n","    tf.tpu.experimental.initialize_tpu_system(resolver)\n","    print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n","    # strategy = tf.distribute.experimental.TPUStrategy(resolver)\n","    strategy = tf.distribute.TPUStrategy(resolver)\n","except ValueError:\n","    print(\"Not connected to a TPU runtime. Using CPU/GPU strategy\")\n","    strategy = tf.distribute.MirroredStrategy()    "],"id":"1AYjQGoU2gFi","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6aS9WdPKYStZ"},"source":["TF records"],"id":"6aS9WdPKYStZ"},{"cell_type":"code","metadata":{"id":"HekihMv7VcSR"},"source":["# Load Dataset\n","\n","data_set_name = [\"test_cv2\", \"test_ori\"]\n","\n","label_info_path = [f'gs://esun--2021/tf_records/{name}/' for name in data_set_name]\n","train_path = [f'gs://esun--2021/tf_records/{name}/train/*' for name in data_set_name]\n","val_path = [f'gs://esun--2021/tf_records/{name}/val/*' for name in data_set_name]"],"id":"HekihMv7VcSR","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PLok4lAFaV5a"},"source":["print(label_info_path)\n","print(train_path)\n","print(val_path)"],"id":"PLok4lAFaV5a","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-dgBh995VcVT"},"source":["# \n","def read_record(example):\n","    features = {\n","        \"image\": tf.io.FixedLenFeature([], tf.string),\n","        \"label\": tf.io.FixedLenFeature([], tf.int64),\n","    }\n","    example = tf.io.parse_single_example(example, features)\n","    \n","    image = tf.image.decode_jpeg(example[\"image\"], channels=3)\n","    image = tf.reshape(image, [224,224,3])\n","    label = tf.cast(example[\"label\"], tf.int32)\n","    \n","    return image, label"],"id":"-dgBh995VcVT","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jE34bSlsVcYl"},"source":["AUTO = tf.data.experimental.AUTOTUNE\n","\n","def prepare_dataset(file_path, order = False):\n","    filenames = []\n","    for f_p in file_path:\n","        filenames.extend(tf.io.gfile.glob(f_p))   \n","    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n","    \n","    # disregard the order of .tfrec files\n","    ignore_order = tf.data.Options()\n","    if order == False:\n","        ignore_order.experimental_deterministic = False\n","    else:\n","        ignore_order.experimental_deterministic = True\n","    dataset = dataset.with_options(ignore_order)\n","    \n","    dataset = dataset.map(read_record, num_parallel_calls=AUTO)\n","        \n","    return dataset\n","\n","train_dataset = prepare_dataset(train_path)\n","val_dataset = prepare_dataset(val_path)"],"id":"jE34bSlsVcYl","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WyzUvr96YWyx"},"source":["# batch_size is scaled with the number of TPU cores\n","batch_size = 64 * strategy.num_replicas_in_sync\n","\n","def auto_aug(image, label):\n","    image = autoaugment.distort_image(image, aug_name='ra_aa', ra_num_layers=1, ra_magnitude=5)\n","    return image, label\n","train_dataset = train_dataset.map(auto_aug, num_parallel_calls=AUTO)\n","train_dataset = train_dataset.shuffle(16384).repeat() \\\n","                .batch(batch_size, drop_remainder=True).prefetch(256)\n","val_dataset = val_dataset.batch(batch_size, drop_remainder=True).prefetch(256)"],"id":"WyzUvr96YWyx","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VkjoyX0feN7p"},"source":["image, label = next(iter(train_dataset))\n","\n","fig, axes = plt.subplots(constrained_layout = True, nrows=3, ncols=3, figsize=(10, 10))\n","\n","for i in range(3):\n","    for j in range(3):\n","        axes[i][j].imshow(image[i*3+j], aspect=\"auto\")\n","        axes[i][j].axis(\"off\")"],"id":"VkjoyX0feN7p","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UIJHmv7_aQbC"},"source":["image, label = next(iter(val_dataset))\n","\n","fig, axes = plt.subplots(constrained_layout = True, nrows=3, ncols=3, figsize=(10, 10))\n","\n","for i in range(3):\n","    for j in range(3):\n","        axes[i][j].imshow(image[i*3+j], aspect=\"auto\")\n","        axes[i][j].axis(\"off\")"],"id":"UIJHmv7_aQbC","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Emu3_XI19DRw"},"source":["class SAMModel(tf.keras.Model):\n","    def __init__(self, model, rho=0.05):\n","        \"\"\"\n","        p, q = 2 for optimal results as suggested in the paper\n","        (Section 2)\n","        \"\"\"\n","        super(SAMModel, self).__init__()\n","        self.model = model\n","        self.rho = rho\n","\n","    def train_step(self, data):\n","        (images, labels) = data\n","        e_ws = []\n","        with tf.GradientTape() as tape:\n","            predictions = self.model(images)\n","            loss = self.compiled_loss(labels, predictions)\n","        trainable_params = self.model.trainable_variables\n","        gradients = tape.gradient(loss, trainable_params)\n","        grad_norm = self._grad_norm(gradients)\n","        scale = self.rho / (grad_norm + 1e-12)\n","        \n","        with tf.GradientTape() as tape:\n","            predictions = self.model(images)\n","            loss = self.compiled_loss(labels, predictions)    \n","        for (grad, param) in zip(gradients, trainable_params):\n","            e_w = grad * scale\n","            param.assign_add(e_w)\n","            e_ws.append(e_w)\n","        sam_gradients = tape.gradient(loss, trainable_params)\n","        for (param, e_w) in zip(trainable_params, e_ws):\n","            param.assign_sub(e_w)\n","        \n","        self.optimizer.apply_gradients(\n","            zip(sam_gradients, trainable_params))\n","\n","        self.compiled_metrics.update_state(labels, predictions)\n","        return {m.name: m.result() for m in self.metrics}\n","\n","    def test_step(self, data):\n","        (images, labels) = data\n","        predictions = self.model(images, training=False)\n","        loss = self.compiled_loss(labels, predictions)\n","        self.compiled_metrics.update_state(labels, predictions)\n","        return {m.name: m.result() for m in self.metrics}\n","\n","    def _grad_norm(self, gradients):\n","        norm = tf.norm(\n","            tf.stack([\n","                tf.norm(grad) for grad in gradients if grad is not None\n","            ])\n","        )\n","        return norm\n","\n","    def call(self, x):\n","        return self.model(x)"],"id":"Emu3_XI19DRw","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IxkOp4nBSGzM"},"source":["def get_model():\n","\n","    inputs = tf.keras.layers.Input(shape=(224, 224, 3))\n","    efficient_model = EfficientNetB0(include_top=True, weights=None, classes=801, input_tensor=inputs)\n","    model = tf.keras.Model(inputs, efficient_model.outputs)\n","\n","    return model\n","\n","with strategy.scope():\n","    \n","    model = SAMModel(get_model())\n","    model.compile(optimizer=tf.keras.optimizers.Adam(), loss=SparseCategoricalFocalLoss(gamma=2), metrics=[\"sparse_categorical_accuracy\"])"],"id":"IxkOp4nBSGzM","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aEcp9Mqa4J5z"},"source":["# Learning rate scheduler\n","def decay(inp):   \n"," \n","    lr_init = 0.00005\n","    # max learning rate is scaled with the number of TPU cores\n","    lr_max = 0.000125 * strategy.num_replicas_in_sync\n","    lin_lr = 5\n","    if inp <= lin_lr:\n","        lr = inp*(lr_max - lr_init) / lin_lr + lr_init\n","    else:\n","        lr = lr_max * np.exp(-0.1*(inp - lin_lr))\n","    lr = lr * 0.1\n","    return lr\n","\n","lrs = LearningRateScheduler(decay)"],"id":"aEcp9Mqa4J5z","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LjVhNPfuuGVb"},"source":["import json\n","import os\n","label_cnt_dict = {}\n","for file_path in label_info_path:\n","  d = tf.io.read_file(filename=os.path.join(file_path, 'label_cnt_dict.json'))\n","\n","  tmp_dict = json.loads(str(d.numpy())[2:-1])\n","  print(file_path)\n","  print(len(tmp_dict))\n","  for k, v in tmp_dict.items():\n","    k = int(k)\n","    if k not in label_cnt_dict:\n","      label_cnt_dict[k] = v\n","    else:\n","      label_cnt_dict[k] += v\n","print(label_cnt_dict)"],"id":"LjVhNPfuuGVb","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4cFJh-UbuQw3"},"source":["\n","label_cnt_lst = []\n","for k, v in label_cnt_dict.items():\n","  label_cnt_lst.extend([k]*v)\n","class_weights = class_weight.compute_class_weight(\n","          'balanced',\n","          np.unique(label_cnt_lst), \n","          label_cnt_lst)\n"],"id":"4cFJh-UbuQw3","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W9fw52kmu01M"},"source":["class_weight = {idx:weight for idx, weight in enumerate(class_weights)}\n"],"id":"W9fw52kmu01M","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NVmawj0Kqkbc"},"source":["print(len(label_cnt_lst))"],"id":"NVmawj0Kqkbc","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zuisrdimvNgg"},"source":["len(class_weight)"],"id":"zuisrdimvNgg","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OvxrpGtd8EA-"},"source":["early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto', restore_best_weights=True)\n","\n","ckpt = tf.keras.callbacks.ModelCheckpoint('./service/fine_tuned_model/efficient_SAM_weights.h5', monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='auto')\n","\n","history = model.fit(train_dataset,\n","            validation_data=val_dataset,\n","            steps_per_epoch=len(label_cnt_lst)//batch_size,\n","            epochs=10,\n","            callbacks=[lrs, ckpt, early_stop])\n"],"id":"OvxrpGtd8EA-","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u21g-KTjj1YU"},"source":["model(tf.zeros((1,224,224,3)))\n","model.load_weights('./service/fine_tuned_model/efficient_SAM_weights.h5')\n","model.model.save('./service/fine_tuned_model/efficient_SAM.hdf5')"],"id":"u21g-KTjj1YU","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mo9W3Q2yndPp"},"source":[""],"id":"Mo9W3Q2yndPp","execution_count":null,"outputs":[]}]}